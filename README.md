# Introduction to PySpark with Machine Learning Practice

This repository contains a Jupyter notebook introducing the use of PySpark for big data processing and machine learning tasks. PySpark is the Python library for Spark programming and it provides a simple API for distributed data processing. It is particularly useful for handling large datasets that would be impractical to process on a single machine.

## Requirements
* Python 3.x
* PySpark
* Jupyter Notebook

## Data
The data used in this repository is housing price data and included in the /data folder. The housing price data includes information on various aspects of housing prices, including median sales prices, average days on market, and number of sales. The data is organized by geographic location and time period, and can be used to analyze trends in the housing market. 

## Conclusion:
This repository provides a good starting point for anyone interested in using PySpark for big data processing and machine learning tasks. The notebook cover the basics of PySpark and demonstrate how to use its machine learning API on a real-world dataset. Feel free to experiment with the code and use it as a basis for your own projects.
